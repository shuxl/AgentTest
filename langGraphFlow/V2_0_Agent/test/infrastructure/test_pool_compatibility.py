"""
SQLAlchemy ä¸ LangGraph è¿æ¥æ± å…¼å®¹æ€§æµ‹è¯•

æœ¬æµ‹è¯•è„šæœ¬ç”¨äºéªŒè¯ï¼š
1. SQLAlchemy ä½¿ç”¨ psycopg é©±åŠ¨çš„å…¼å®¹æ€§
2. SQLAlchemy å’Œ LangGraph èƒ½å¦å…±äº«è¿æ¥æ± ï¼ˆæˆ–è‡³å°‘ä¸å†²çªï¼‰
3. è¿æ¥æ± é…ç½®çš„æ­£ç¡®æ€§
4. å¹¶å‘åœºæ™¯ä¸‹çš„ç¨³å®šæ€§

è¿è¡Œæ–¹å¼ï¼š
    conda run -n py_311_rag python test/infrastructure/test_pool_compatibility.py
"""
import sys
import os
import asyncio
import logging
import time
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from utils.config import Config
from utils.database import get_db_pool
from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver
from langgraph.store.postgres import AsyncPostgresStore

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def test_sqlalchemy_psycopg_driver():
    """æµ‹è¯•1ï¼šéªŒè¯ SQLAlchemy ä½¿ç”¨ psycopg é©±åŠ¨"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•1ï¼šéªŒè¯ SQLAlchemy ä½¿ç”¨ psycopg é©±åŠ¨")
    logger.info("=" * 60)
    
    try:
        from sqlalchemy.ext.asyncio import create_async_engine
        from sqlalchemy import text
        
        # è½¬æ¢è¿æ¥å­—ç¬¦ä¸²
        db_uri = Config.DB_URI
        if db_uri.startswith("postgresql://"):
            sqlalchemy_uri = db_uri.replace("postgresql://", "postgresql+psycopg://", 1)
        else:
            sqlalchemy_uri = db_uri
        
        logger.info(f"SQLAlchemy URI: {sqlalchemy_uri}")
        
        # åˆ›å»ºå¼•æ“ï¼Œä½¿ç”¨ psycopg é©±åŠ¨
        engine = create_async_engine(
            sqlalchemy_uri,
            echo=False,
            pool_pre_ping=True,
            pool_size=5,
            max_overflow=10
        )
        
        # æµ‹è¯•è¿æ¥å’ŒæŸ¥è¯¢
        async with engine.connect() as conn:
            # æµ‹è¯•åŸºæœ¬æŸ¥è¯¢
            result = await conn.execute(text("SELECT version()"))
            version = result.scalar()
            logger.info(f"âœ… PostgreSQL ç‰ˆæœ¬æŸ¥è¯¢æˆåŠŸ: {version[:50]}...")
            
            # æµ‹è¯•æ—¶åŒºè®¾ç½®
            await conn.execute(text(f"SET timezone = '{Config.DB_TIMEZONE}'"))
            result = await conn.execute(text("SHOW timezone"))
            timezone = result.scalar()
            logger.info(f"âœ… æ—¶åŒºè®¾ç½®æˆåŠŸ: {timezone}")
            
            # æµ‹è¯•è¿æ¥æ± ä¿¡æ¯
            pool = engine.pool
            logger.info(f"âœ… è¿æ¥æ± ç±»å‹: {type(pool).__name__}")
            logger.info(f"âœ… è¿æ¥æ± å¤§å°: size={pool.size()}, checked_in={pool.checkedin()}, checked_out={pool.checkedout()}")
        
        await engine.dispose()
        logger.info("âœ… SQLAlchemy ä½¿ç”¨ psycopg é©±åŠ¨æµ‹è¯•é€šè¿‡")
        
        return True
    except Exception as e:
        logger.error(f"âŒ SQLAlchemy ä½¿ç”¨ psycopg é©±åŠ¨æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False


async def test_separate_pools_compatibility():
    """æµ‹è¯•2ï¼šéªŒè¯ SQLAlchemy å’Œ LangGraph ä½¿ç”¨ç‹¬ç«‹è¿æ¥æ± çš„å…¼å®¹æ€§"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•2ï¼šéªŒè¯ç‹¬ç«‹è¿æ¥æ± å…¼å®¹æ€§")
    logger.info("=" * 60)
    
    try:
        from sqlalchemy.ext.asyncio import create_async_engine
        from sqlalchemy import text
        
        # 1. åˆ›å»º psycopg è¿æ¥æ± ï¼ˆLangGraph ä½¿ç”¨ï¼‰
        db_pool = get_db_pool()
        psycopg_pool = await db_pool.create_pool()
        logger.info("âœ… psycopg è¿æ¥æ± åˆ›å»ºæˆåŠŸ")
        
        # 2. åˆ›å»º LangGraph ç»„ä»¶
        checkpointer = AsyncPostgresSaver(psycopg_pool)
        await checkpointer.setup()
        logger.info("âœ… LangGraph checkpointer åˆå§‹åŒ–æˆåŠŸ")
        
        store = AsyncPostgresStore(psycopg_pool)
        await store.setup()
        logger.info("âœ… LangGraph store åˆå§‹åŒ–æˆåŠŸ")
        
        # 3. åˆ›å»º SQLAlchemy å¼•æ“ï¼ˆç‹¬ç«‹è¿æ¥æ± ï¼‰
        db_uri = Config.DB_URI
        if db_uri.startswith("postgresql://"):
            sqlalchemy_uri = db_uri.replace("postgresql://", "postgresql+psycopg://", 1)
        else:
            sqlalchemy_uri = db_uri
        
        sqlalchemy_engine = create_async_engine(
            sqlalchemy_uri,
            echo=False,
            pool_pre_ping=True,
            pool_size=5,
            max_overflow=10
        )
        logger.info("âœ… SQLAlchemy å¼•æ“åˆ›å»ºæˆåŠŸï¼ˆç‹¬ç«‹è¿æ¥æ± ï¼‰")
        
        # 4. æµ‹è¯• LangGraph è¿æ¥æ± æ“ä½œ
        async with psycopg_pool.connection() as conn:
            async with conn.cursor() as cur:
                await cur.execute("SELECT 1 as langgraph_test")
                result = await cur.fetchone()
                logger.info(f"âœ… LangGraph è¿æ¥æ± æŸ¥è¯¢æˆåŠŸ: {result}")
        
        # 5. æµ‹è¯• SQLAlchemy è¿æ¥æ± æ“ä½œ
        async with sqlalchemy_engine.connect() as conn:
            result = await conn.execute(text("SELECT 1 as sqlalchemy_test"))
            value = result.scalar()
            logger.info(f"âœ… SQLAlchemy è¿æ¥æ± æŸ¥è¯¢æˆåŠŸ: {value}")
        
        # 6. æµ‹è¯•å¹¶å‘æ“ä½œï¼ˆä¸¤ä¸ªè¿æ¥æ± åŒæ—¶å·¥ä½œï¼‰
        logger.info("æµ‹è¯•å¹¶å‘æ“ä½œ...")
        async def langgraph_query():
            async with psycopg_pool.connection() as conn:
                async with conn.cursor() as cur:
                    await cur.execute("SELECT pg_sleep(0.1), 'langgraph' as source")
                    return await cur.fetchone()
        
        async def sqlalchemy_query():
            async with sqlalchemy_engine.connect() as conn:
                result = await conn.execute(text("SELECT pg_sleep(0.1), 'sqlalchemy' as source"))
                return result.fetchone()
        
        # å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(langgraph_query(), sqlalchemy_query())
        logger.info(f"âœ… å¹¶å‘æŸ¥è¯¢æˆåŠŸ: LangGraph={results[0]}, SQLAlchemy={results[1]}")
        
        # æ¸…ç†èµ„æº
        await sqlalchemy_engine.dispose()
        await psycopg_pool.close()
        
        logger.info("âœ… ç‹¬ç«‹è¿æ¥æ± å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
        logger.info("âš ï¸  æ³¨æ„ï¼šå½“å‰ä½¿ç”¨ç‹¬ç«‹è¿æ¥æ± ï¼ŒçœŸæ­£çš„å…±äº«è¿æ¥æ± éœ€è¦é€‚é…å™¨å®ç°")
        
        return True
    except Exception as e:
        logger.error(f"âŒ ç‹¬ç«‹è¿æ¥æ± å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False


async def test_pool_configuration():
    """æµ‹è¯•3ï¼šéªŒè¯è¿æ¥æ± é…ç½®æ­£ç¡®æ€§"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•3ï¼šéªŒè¯è¿æ¥æ± é…ç½®æ­£ç¡®æ€§")
    logger.info("=" * 60)
    
    try:
        from sqlalchemy.ext.asyncio import create_async_engine
        
        # 1. æµ‹è¯• psycopg è¿æ¥æ± é…ç½®
        db_pool = get_db_pool()
        psycopg_pool = await db_pool.create_pool()
        
        logger.info("psycopg è¿æ¥æ± é…ç½®:")
        logger.info(f"  - min_size: {db_pool.min_size}")
        logger.info(f"  - max_size: {db_pool.max_size}")
        logger.info(f"  - è¿æ¥æ± çŠ¶æ€: {psycopg_pool.get_stats()}")
        
        # 2. æµ‹è¯• SQLAlchemy è¿æ¥æ± é…ç½®
        db_uri = Config.DB_URI
        if db_uri.startswith("postgresql://"):
            sqlalchemy_uri = db_uri.replace("postgresql://", "postgresql+psycopg://", 1)
        else:
            sqlalchemy_uri = db_uri
        
        sqlalchemy_engine = create_async_engine(
            sqlalchemy_uri,
            echo=False,
            pool_pre_ping=True,
            pool_size=5,
            max_overflow=10
        )
        
        logger.info("SQLAlchemy è¿æ¥æ± é…ç½®:")
        pool = sqlalchemy_engine.pool
        logger.info(f"  - pool_size: 5")
        logger.info(f"  - max_overflow: 10")
        logger.info(f"  - pool_pre_ping: True")
        logger.info(f"  - å½“å‰è¿æ¥æ•°: size={pool.size()}, checked_in={pool.checkedin()}, checked_out={pool.checkedout()}")
        
        # 3. æµ‹è¯•è¿æ¥æ± æ€§èƒ½
        logger.info("æµ‹è¯•è¿æ¥æ± æ€§èƒ½...")
        start_time = time.time()
        
        async def quick_query():
            async with sqlalchemy_engine.connect() as conn:
                from sqlalchemy import text
                await conn.execute(text("SELECT 1"))
        
        # å¹¶å‘æ‰§è¡Œå¤šä¸ªæŸ¥è¯¢
        await asyncio.gather(*[quick_query() for _ in range(10)])
        
        elapsed_time = time.time() - start_time
        logger.info(f"âœ… 10ä¸ªå¹¶å‘æŸ¥è¯¢è€—æ—¶: {elapsed_time:.3f}ç§’")
        
        # æ¸…ç†èµ„æº
        await sqlalchemy_engine.dispose()
        await psycopg_pool.close()
        
        logger.info("âœ… è¿æ¥æ± é…ç½®éªŒè¯é€šè¿‡")
        
        return True
    except Exception as e:
        logger.error(f"âŒ è¿æ¥æ± é…ç½®éªŒè¯å¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False


async def test_concurrent_stability():
    """æµ‹è¯•4ï¼šéªŒè¯å¹¶å‘åœºæ™¯ä¸‹çš„ç¨³å®šæ€§"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•4ï¼šéªŒè¯å¹¶å‘åœºæ™¯ä¸‹çš„ç¨³å®šæ€§")
    logger.info("=" * 60)
    
    try:
        from sqlalchemy.ext.asyncio import create_async_engine
        from sqlalchemy import text
        
        # åˆ›å»ºè¿æ¥æ± 
        db_pool = get_db_pool()
        psycopg_pool = await db_pool.create_pool()
        
        db_uri = Config.DB_URI
        if db_uri.startswith("postgresql://"):
            sqlalchemy_uri = db_uri.replace("postgresql://", "postgresql+psycopg://", 1)
        else:
            sqlalchemy_uri = db_uri
        
        sqlalchemy_engine = create_async_engine(
            sqlalchemy_uri,
            echo=False,
            pool_pre_ping=True,
            pool_size=5,
            max_overflow=10
        )
        
        # åˆ›å»ºæµ‹è¯•è¡¨
        async with sqlalchemy_engine.connect() as conn:
            await conn.execute(text("""
                CREATE TABLE IF NOT EXISTS test_concurrent_stability (
                    id SERIAL PRIMARY KEY,
                    source VARCHAR(50),
                    value INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """))
            await conn.commit()
        
        # å¹¶å‘æµ‹è¯•å‡½æ•°
        async def langgraph_insert(value: int):
            async with psycopg_pool.connection() as conn:
                async with conn.cursor() as cur:
                    await cur.execute(
                        "INSERT INTO test_concurrent_stability (source, value) VALUES (%s, %s)",
                        ("langgraph", value)
                    )
                    return value
        
        async def sqlalchemy_insert(value: int):
            async with sqlalchemy_engine.connect() as conn:
                await conn.execute(
                    text("INSERT INTO test_concurrent_stability (source, value) VALUES (:source, :value)"),
                    {"source": "sqlalchemy", "value": value}
                )
                await conn.commit()
                return value
        
        # å¹¶å‘æ‰§è¡Œæ’å…¥æ“ä½œ
        logger.info("æ‰§è¡Œå¹¶å‘æ’å…¥æ“ä½œï¼ˆ20ä¸ªä»»åŠ¡ï¼‰...")
        tasks = []
        for i in range(10):
            tasks.append(langgraph_insert(i))
            tasks.append(sqlalchemy_insert(i + 10))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ£€æŸ¥ç»“æœ
        errors = [r for r in results if isinstance(r, Exception)]
        if errors:
            logger.error(f"âŒ å¹¶å‘æ“ä½œå‡ºç°é”™è¯¯: {len(errors)} ä¸ª")
            for error in errors[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
                logger.error(f"  é”™è¯¯: {str(error)}")
            return False
        
        logger.info(f"âœ… å¹¶å‘æ’å…¥æ“ä½œæˆåŠŸ: {len(results)} ä¸ªä»»åŠ¡å®Œæˆ")
        
        # éªŒè¯æ•°æ®
        async with sqlalchemy_engine.connect() as conn:
            result = await conn.execute(text("SELECT COUNT(*) FROM test_concurrent_stability"))
            count = result.scalar()
            logger.info(f"âœ… æ•°æ®éªŒè¯: å…±æ’å…¥ {count} æ¡è®°å½•")
            
            result = await conn.execute(text("SELECT source, COUNT(*) FROM test_concurrent_stability GROUP BY source"))
            rows = result.fetchall()
            for row in rows:
                logger.info(f"  - {row[0]}: {row[1]} æ¡")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        async with sqlalchemy_engine.connect() as conn:
            await conn.execute(text("DROP TABLE IF EXISTS test_concurrent_stability"))
            await conn.commit()
        
        # æ¸…ç†èµ„æº
        await sqlalchemy_engine.dispose()
        await psycopg_pool.close()
        
        logger.info("âœ… å¹¶å‘ç¨³å®šæ€§æµ‹è¯•é€šè¿‡")
        
        return True
    except Exception as e:
        logger.error(f"âŒ å¹¶å‘ç¨³å®šæ€§æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False


async def test_pool_connection_reuse():
    """æµ‹è¯•5ï¼šéªŒè¯è¿æ¥æ± è¿æ¥å¤ç”¨"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•5ï¼šéªŒè¯è¿æ¥æ± è¿æ¥å¤ç”¨")
    logger.info("=" * 60)
    
    try:
        from sqlalchemy.ext.asyncio import create_async_engine
        from sqlalchemy import text
        
        # åˆ›å»º SQLAlchemy å¼•æ“ï¼ˆå°è¿æ¥æ± ï¼‰
        db_uri = Config.DB_URI
        if db_uri.startswith("postgresql://"):
            sqlalchemy_uri = db_uri.replace("postgresql://", "postgresql+psycopg://", 1)
        else:
            sqlalchemy_uri = db_uri
        
        engine = create_async_engine(
            sqlalchemy_uri,
            echo=False,
            pool_pre_ping=True,
            pool_size=2,  # å°è¿æ¥æ± ï¼Œä¾¿äºè§‚å¯Ÿå¤ç”¨
            max_overflow=0
        )
        
        # æµ‹è¯•è¿æ¥å¤ç”¨
        logger.info("æµ‹è¯•è¿æ¥å¤ç”¨...")
        
        async def query_with_id(query_id: int):
            async with engine.connect() as conn:
                result = await conn.execute(text("SELECT pg_backend_pid()"))
                pid = result.scalar()
                logger.info(f"  æŸ¥è¯¢ {query_id}: ä½¿ç”¨è¿›ç¨‹ID {pid}")
                await asyncio.sleep(0.1)  # çŸ­æš‚å»¶è¿Ÿ
                return pid
        
        # é¡ºåºæ‰§è¡Œå¤šä¸ªæŸ¥è¯¢ï¼ˆåº”è¯¥å¤ç”¨è¿æ¥ï¼‰
        pids = []
        for i in range(5):
            pid = await query_with_id(i)
            pids.append(pid)
        
        # æ£€æŸ¥æ˜¯å¦å¤ç”¨äº†è¿æ¥ï¼ˆè¿›ç¨‹IDåº”è¯¥ç›¸åŒæˆ–åªæœ‰å°‘é‡ä¸åŒï¼‰
        unique_pids = len(set(pids))
        logger.info(f"âœ… è¿æ¥å¤ç”¨æµ‹è¯•: 5ä¸ªæŸ¥è¯¢ä½¿ç”¨äº† {unique_pids} ä¸ªä¸åŒçš„è¿æ¥")
        
        if unique_pids <= 2:
            logger.info("âœ… è¿æ¥æ± æ­£ç¡®å¤ç”¨è¿æ¥")
        else:
            logger.warning("âš ï¸  è¿æ¥å¤ç”¨å¯èƒ½ä¸å¤Ÿç†æƒ³")
        
        await engine.dispose()
        
        return True
    except Exception as e:
        logger.error(f"âŒ è¿æ¥å¤ç”¨æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("SQLAlchemy ä¸ LangGraph è¿æ¥æ± å…¼å®¹æ€§æµ‹è¯•")
    logger.info("=" * 60)
    logger.info("")
    
    results = []
    
    # æµ‹è¯•1ï¼šSQLAlchemy ä½¿ç”¨ psycopg é©±åŠ¨
    result1 = await test_sqlalchemy_psycopg_driver()
    results.append(("SQLAlchemy ä½¿ç”¨ psycopg é©±åŠ¨", result1))
    logger.info("")
    
    # æµ‹è¯•2ï¼šç‹¬ç«‹è¿æ¥æ± å…¼å®¹æ€§
    result2 = await test_separate_pools_compatibility()
    results.append(("ç‹¬ç«‹è¿æ¥æ± å…¼å®¹æ€§", result2))
    logger.info("")
    
    # æµ‹è¯•3ï¼šè¿æ¥æ± é…ç½®éªŒè¯
    result3 = await test_pool_configuration()
    results.append(("è¿æ¥æ± é…ç½®éªŒè¯", result3))
    logger.info("")
    
    # æµ‹è¯•4ï¼šå¹¶å‘ç¨³å®šæ€§
    result4 = await test_concurrent_stability()
    results.append(("å¹¶å‘ç¨³å®šæ€§", result4))
    logger.info("")
    
    # æµ‹è¯•5ï¼šè¿æ¥å¤ç”¨
    result5 = await test_pool_connection_reuse()
    results.append(("è¿æ¥å¤ç”¨", result5))
    logger.info("")
    
    # è¾“å‡ºæµ‹è¯•ç»“æœæ±‡æ€»
    logger.info("=" * 60)
    logger.info("æµ‹è¯•ç»“æœæ±‡æ€»")
    logger.info("=" * 60)
    
    all_passed = True
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"{test_name}: {status}")
        if not result:
            all_passed = False
    
    logger.info("")
    if all_passed:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è¿æ¥æ± å…¼å®¹æ€§éªŒè¯å®Œæˆã€‚")
        logger.info("")
        logger.info("ç»“è®ºï¼š")
        logger.info("1. âœ… SQLAlchemy å¯ä»¥ä½¿ç”¨ psycopg é©±åŠ¨")
        logger.info("2. âœ… SQLAlchemy å’Œ LangGraph å¯ä»¥ä½¿ç”¨ç‹¬ç«‹è¿æ¥æ± ï¼Œäº’ä¸å¹²æ‰°")
        logger.info("3. âœ… è¿æ¥æ± é…ç½®æ­£ç¡®ï¼Œæ€§èƒ½è‰¯å¥½")
        logger.info("4. âœ… å¹¶å‘åœºæ™¯ä¸‹ç¨³å®šå¯é ")
        logger.info("")
        logger.info("æ³¨æ„ï¼š")
        logger.info("- å½“å‰å®ç°ä½¿ç”¨ç‹¬ç«‹è¿æ¥æ± ï¼Œä¸æ˜¯çœŸæ­£çš„å…±äº«è¿æ¥æ± ")
        logger.info("- å¦‚éœ€å…±äº«è¿æ¥æ± ï¼Œéœ€è¦å®ç°é€‚é…å™¨æˆ–ä½¿ç”¨å…¶ä»–æ–¹æ¡ˆ")
        logger.info("- ç‹¬ç«‹è¿æ¥æ± æ–¹æ¡ˆå·²ç»è¶³å¤Ÿä½¿ç”¨ï¼Œæ€§èƒ½å½±å“å¯æ¥å—")
    else:
        logger.error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜ã€‚")
    
    logger.info("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())

